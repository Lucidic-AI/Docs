---
title: Workflow Sandbox
description: Dive into a full breakdown of one agent run — replay, inspect, evaluate, and debug every decision.
---

# 🧪 Workflow Sandbox

The **Workflow Sandbox** is your deep-dive view into a single agent run — also known as a [Session](/sessions).

It’s where observability meets usability: you can **replay the session**, **inspect every step**, **explore the underlying events**, and **evaluate performance** using rubrics — all in one place.

---

## 🧠 What It Shows

At the top of the Workflow Sandbox, you’ll see:

### 1. 📝 Task Overview
- The task string supplied to the agent at the start of the session

### 2. 📊 Session Stats
- Session Evaluation (read more about it [here](/sessions#evaluation-and-scoring))
- Is Successful (read more about it [here](/sessions#evaluation-and-scoring))
- Cost
- Time 
- Total Steps
- Repeated Steps
- Average Steps per node 
> 📷 _![api key2](/images/ws1.png)_

---
🧠 **Pro tip:** Hover over the session evaluation or the success/failure flag to see a the description!! 


## 🧮 Rubric Evaluations

Below the overview, you’ll find any evaluation rubrics attached to this session. Read more about rubrics [here](/features/rubrics).

- Each criterion is scored and explained
- The **Lucidic default rubric** runs on every session automatically
- Custom rubrics can be attached per Agent when running a session

🧠 **Pro tip:**: The description of why you got a certain score for a given criterion is below the score, so you can actually see why each of your criteria got a certain score! 

> 📷 _![rubric](/images/ws2.png)_

---

## 📚 Quick Access: Prompt DB

You can open the [Prompt DB](/features/prompt-db) directly from the session:

- Quickly view which prompt was used
- Test changes or view version history
- Add tags to quickly iterate on prompts



---
## 🧭 Session Replay: Step Trajectory Graph

Next, you’ll see a **Session-specific graph** — a mini version of the [Workflow Trajectory](/features/workflow-trajectory), scoped to just this one session.

- **Nodes** = states visited
- **Edges** = actions taken
- **Grouped** = similar states are clustered (e.g. looping or retrying)

🧠 **Pro tip:**: Clicking a node opens a full breakdown of that **Step** below the graph!

> 📷 _![trajectory](/images/ws3.png)_

---

## 🕰 Timeline Navigation

Two synced timelines appear below:

### 🪜 Step Timeline
- Shows the ordered sequence of Steps
- Clicking a step:
  - Advances the graph to that state
  - Opens the step detail panel
- Step detail panel shows:
  - Basic Information: Start time, duration, Cost
  - Evaluation: Status, step eval score, eval description
  - State overview: Goal, Action, State
  - Image of state

> 📷 _![step detail](/images/ws4.png)_

🧠 **Pro tip:**: Use arrow keys to quickly go from one step to the next.

### ⚙️ Event Timeline (within Step)
- Shows all [Events](/events) that occurred in that step (e.g. LLM calls, tool invocations)
- Clicking an event shows:
  - Request/response
  - Images used (if any)
  - Cost
  - Model used
  - Any errors or retries
  - Time travels (read more about them [here](/features/time-travel))
  - Pretty vs raw request/response

> 📷 _![event timeline](/images/ws5.png)_

🧠 **Pro tip:**: If your LLM calls are super cluttered, use our pretty text which is built in! It's the wand and will show you your text in a readable format. 

---

## 🧰 Use Cases

The Workflow Sandbox is where you:

- Debug a failed run
- Investigate edge cases
- Replay odd behavior
- Evaluate agent consistency
- Identify root causes of errors
- Understand how a prompt or model change affected logic

---

## 🔮 Future Features

- Annotate steps or events
- Inline prompt diffing
- Attach notes to runs for team reviews or QA

---

## 🔗 Related Docs

- [Sessions](/sessions)
- [Steps](/steps)
- [Events](/events)
- [Rubrics](/features/rubrics)
- [Prompt DB](/features/prompt-db)
- [Workflow Trajectory](/features/workflow-trajectory)

---