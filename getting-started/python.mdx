---
title: Using the Python SDK
description: Learn how to instrument your agent with Lucidic using the Python SDK.
---

# 🐍 Using the Python SDK

Once you've [installed Lucidic](/getting-started/installation), you're ready to start recording your agent's behavior, step by step.

This guide walks you through how to initialize a session, track steps and events, and optionally pull prompts from our [Prompt DB](/features/prompt-db).

---

## 🚀 Step 1: Import & Initialize

```python
import lucidicai as lai

lai.init(
    session_name="search_wikipedia",
    lucidic_api_key="your-api-key",   # Or use env var: LUCIDIC_API_KEY
    agent_id="your-agent-id",         # Or use env var: LUCIDIC_AGENT_ID
    task="Search Wikipedia for Elon Musk's biography",
    provider="openai",                # "openai", "anthropic", or "langchain"
    mass_sim_id="your-mass-sim-id",   # Optional
    rubrics=["default", "custom_score"]  # Optional
)
```

### ⚙️ Environment Variable Support

You can skip `lucidic_api_key` and `agent_id` if you set:

```bash
export LUCIDIC_API_KEY=your-api-key
export LUCIDIC_AGENT_ID=your-agent-id
```

---

## 🧭 Step 2: Instrument Agent Steps

Use `create_step()` and `end_step()` around your step logic. Each step should represent a meaningful action or decision point.

```python
lai.create_step(state="Home page", goal="Navigate to search")

# Your agent logic here...

lai.end_step(is_successful=True, action="Clicked search")
```

> Only **one step can be active at a time**, so be sure to end a step before creating a new one.

Optional fields include:
- `state`, `action`, `goal`
- `eval_score`, `eval_description`
- `screenshot` or `screenshot_path`

---

## ⚙️ Step Updates

You can update steps mid-run or retroactively:

```python
lai.update_step(action="Updated description")
lai.update_previous_step(index=-1, eval_score=0.5)
```

---

## ⚙️ Step Events

If your agent has tool calls or LLM usage, track them as **events** within each step.

```python
lai.create_event(description="OpenAI call")
# Do your LLM call...
lai.end_event(is_successful=True, result="Summary generated")
```

You can also use `update_event()` and `update_previous_event()` to patch logs.

> LLM calls from supported providers like OpenAI and Anthropic are **automatically captured** into events when you set the `provider` in `init()`.

---

## 📥 Step 3: (Optional) Pull Prompts from Prompt DB

Use Lucidic’s [Prompt DB](/features/prompt-db) to version and serve prompts dynamically:

```python
prompt = lai.get_prompt(
    prompt_name="summarize_webpage",
    variables={"page_text": "Stanford University is..."},
    label="production",
    cache_ttl=60
)
```

- `{{variable}}` placeholders will be replaced using your dictionary
- Missing keys will raise an error
- Unreplaced variables will trigger a warning

---

## 🧼 Session Cleanup

Your session will automatically end gracefully when the script exits (via `atexit` handler), but you can also end it explicitly:

```python
lai.end_session(is_successful=True)
```

---

## 🧪 Full Example

```python
import lucidicai as lai

lai.init(
    session_name="wiki_search",
    agent_id="agent-123",
    provider="openai",
    task="Search for Stanford University",
    rubrics=["default"]
)

lai.create_step(state="Home", goal="Search for Stanford")

# (Your logic here)

lai.create_event(description="OpenAI call")
# (Your LLM call)
lai.end_event(is_successful=True, result="Found Stanford")

lai.end_step(is_successful=True, action="Used search")

lai.end_session(is_successful=True)
```

---

## 🔗 Next Steps

- [Evaluate Sessions with Rubrics](/features/rubrics)
- [Run Mass Simulations](/mass-simulations)
- [View Session Replays in the Workflow Sandbox](/features/workflow-sandbox)

---